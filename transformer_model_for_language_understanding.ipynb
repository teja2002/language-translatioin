{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portuguese to English text conversion\n",
    "\n",
    "we are training a transformer model to to translate portuguese to english\n",
    "A transformer model handles variable-sized input using stacks of self-attention layers instead of RNNs or CNNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary datsets\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downloading the dataset\n",
    "\n",
    "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "#splitting the datset into training set and validation set\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom subwords tokenizer from the training dataset.\n",
    "\n",
    "tfds.deprecated.text.SubwordTextEncoder.build_from_corpus is used To generate a vocabulary from a corpus.\n",
    "\n",
    "would take values as corpus generator, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "#tokenized string\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "#original string\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a start and end token to the input and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "        lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "        lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to use Dataset.map to apply this function to each element of the dataset. Dataset.map runs in graph mode.\n",
    "\n",
    "Graph tensors do not have a value.\n",
    "\n",
    "In graph mode you can only use TensorFlow Ops and functions.\n",
    "\n",
    "\n",
    "So you can't .map this function directly: You need to wrap it in a tf.py_function. The tf.py_function will pass regular tensors (with a value and a .numpy() method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                          tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)#\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next() function returns the next item in an iterator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]], dtype=int64)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P E(pos,2i) = sin(pos/10000^(2i/d))\n",
    "## P E(pos,2i+1) = cos(pos/10000^(2i/d))\n",
    "\n",
    "you can check the original paper - Positional Encoding to Control Output Sequence Length\n",
    "\n",
    "\n",
    "d/d_model = embedding dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the equation which are stated above\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Masking\n",
    "\n",
    "\n",
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input.  The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "\n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.0125 Accuracy 0.7546\n",
      "Epoch 1 Batch 50 Loss 1.0622 Accuracy 0.7491\n",
      "Epoch 1 Batch 100 Loss 1.0652 Accuracy 0.7492\n",
      "Epoch 1 Batch 150 Loss 1.0745 Accuracy 0.7474\n",
      "Epoch 1 Batch 200 Loss 1.0814 Accuracy 0.7460\n",
      "Epoch 1 Batch 250 Loss 1.0902 Accuracy 0.7444\n",
      "Epoch 1 Batch 300 Loss 1.0971 Accuracy 0.7432\n",
      "Epoch 1 Batch 350 Loss 1.1025 Accuracy 0.7418\n",
      "Epoch 1 Batch 400 Loss 1.1097 Accuracy 0.7404\n",
      "Epoch 1 Batch 450 Loss 1.1150 Accuracy 0.7393\n",
      "Epoch 1 Batch 500 Loss 1.1197 Accuracy 0.7386\n",
      "Epoch 1 Batch 550 Loss 1.1260 Accuracy 0.7375\n",
      "Epoch 1 Batch 600 Loss 1.1308 Accuracy 0.7366\n",
      "Epoch 1 Batch 650 Loss 1.1368 Accuracy 0.7355\n",
      "Epoch 1 Batch 700 Loss 1.1426 Accuracy 0.7345\n",
      "Epoch 1 Loss 1.1431 Accuracy 0.7344\n",
      "Time taken for 1 epoch: 406.90173840522766 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.9380 Accuracy 0.7629\n",
      "Epoch 2 Batch 50 Loss 1.0160 Accuracy 0.7572\n",
      "Epoch 2 Batch 100 Loss 1.0235 Accuracy 0.7562\n",
      "Epoch 2 Batch 150 Loss 1.0311 Accuracy 0.7550\n",
      "Epoch 2 Batch 200 Loss 1.0421 Accuracy 0.7529\n",
      "Epoch 2 Batch 250 Loss 1.0507 Accuracy 0.7515\n",
      "Epoch 2 Batch 300 Loss 1.0589 Accuracy 0.7498\n",
      "Epoch 2 Batch 350 Loss 1.0655 Accuracy 0.7484\n",
      "Epoch 2 Batch 400 Loss 1.0702 Accuracy 0.7473\n",
      "Epoch 2 Batch 450 Loss 1.0750 Accuracy 0.7466\n",
      "Epoch 2 Batch 500 Loss 1.0809 Accuracy 0.7457\n",
      "Epoch 2 Batch 550 Loss 1.0876 Accuracy 0.7445\n",
      "Epoch 2 Batch 600 Loss 1.0916 Accuracy 0.7437\n",
      "Epoch 2 Batch 650 Loss 1.0975 Accuracy 0.7427\n",
      "Epoch 2 Batch 700 Loss 1.1034 Accuracy 0.7415\n",
      "Epoch 2 Loss 1.1037 Accuracy 0.7415\n",
      "Time taken for 1 epoch: 305.0864028930664 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.9397 Accuracy 0.7751\n",
      "Epoch 3 Batch 50 Loss 0.9886 Accuracy 0.7626\n",
      "Epoch 3 Batch 100 Loss 0.9932 Accuracy 0.7619\n",
      "Epoch 3 Batch 150 Loss 1.0045 Accuracy 0.7595\n",
      "Epoch 3 Batch 200 Loss 1.0091 Accuracy 0.7584\n",
      "Epoch 3 Batch 250 Loss 1.0122 Accuracy 0.7584\n",
      "Epoch 3 Batch 300 Loss 1.0200 Accuracy 0.7568\n",
      "Epoch 3 Batch 350 Loss 1.0286 Accuracy 0.7548\n",
      "Epoch 3 Batch 400 Loss 1.0365 Accuracy 0.7534\n",
      "Epoch 3 Batch 450 Loss 1.0419 Accuracy 0.7522\n",
      "Epoch 3 Batch 500 Loss 1.0474 Accuracy 0.7511\n",
      "Epoch 3 Batch 550 Loss 1.0543 Accuracy 0.7498\n",
      "Epoch 3 Batch 600 Loss 1.0602 Accuracy 0.7488\n",
      "Epoch 3 Batch 650 Loss 1.0647 Accuracy 0.7479\n",
      "Epoch 3 Batch 700 Loss 1.0705 Accuracy 0.7470\n",
      "Epoch 3 Loss 1.0710 Accuracy 0.7468\n",
      "Time taken for 1 epoch: 305.6395425796509 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.9828 Accuracy 0.7729\n",
      "Epoch 4 Batch 50 Loss 0.9603 Accuracy 0.7681\n",
      "Epoch 4 Batch 100 Loss 0.9665 Accuracy 0.7676\n",
      "Epoch 4 Batch 150 Loss 0.9757 Accuracy 0.7657\n",
      "Epoch 4 Batch 200 Loss 0.9849 Accuracy 0.7633\n",
      "Epoch 4 Batch 250 Loss 0.9891 Accuracy 0.7622\n",
      "Epoch 4 Batch 300 Loss 0.9949 Accuracy 0.7609\n",
      "Epoch 4 Batch 350 Loss 1.0021 Accuracy 0.7592\n",
      "Epoch 4 Batch 400 Loss 1.0056 Accuracy 0.7586\n",
      "Epoch 4 Batch 450 Loss 1.0093 Accuracy 0.7578\n",
      "Epoch 4 Batch 500 Loss 1.0158 Accuracy 0.7567\n",
      "Epoch 4 Batch 550 Loss 1.0210 Accuracy 0.7558\n",
      "Epoch 4 Batch 600 Loss 1.0271 Accuracy 0.7545\n",
      "Epoch 4 Batch 650 Loss 1.0330 Accuracy 0.7536\n",
      "Epoch 4 Batch 700 Loss 1.0386 Accuracy 0.7525\n",
      "Epoch 4 Loss 1.0387 Accuracy 0.7525\n",
      "Time taken for 1 epoch: 301.9817523956299 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.9030 Accuracy 0.7915\n",
      "Epoch 5 Batch 50 Loss 0.9186 Accuracy 0.7750\n",
      "Epoch 5 Batch 100 Loss 0.9292 Accuracy 0.7726\n",
      "Epoch 5 Batch 150 Loss 0.9423 Accuracy 0.7698\n",
      "Epoch 5 Batch 200 Loss 0.9519 Accuracy 0.7684\n",
      "Epoch 5 Batch 250 Loss 0.9589 Accuracy 0.7676\n",
      "Epoch 5 Batch 300 Loss 0.9642 Accuracy 0.7666\n",
      "Epoch 5 Batch 350 Loss 0.9707 Accuracy 0.7653\n",
      "Epoch 5 Batch 400 Loss 0.9761 Accuracy 0.7641\n",
      "Epoch 5 Batch 450 Loss 0.9815 Accuracy 0.7631\n",
      "Epoch 5 Batch 500 Loss 0.9861 Accuracy 0.7624\n",
      "Epoch 5 Batch 550 Loss 0.9924 Accuracy 0.7612\n",
      "Epoch 5 Batch 600 Loss 0.9988 Accuracy 0.7599\n",
      "Epoch 5 Batch 650 Loss 1.0056 Accuracy 0.7587\n",
      "Epoch 5 Batch 700 Loss 1.0097 Accuracy 0.7578\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-5\n",
      "Epoch 5 Loss 1.0097 Accuracy 0.7578\n",
      "Time taken for 1 epoch: 303.44133377075195 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9998 Accuracy 0.7707\n",
      "Epoch 6 Batch 50 Loss 0.9000 Accuracy 0.7802\n",
      "Epoch 6 Batch 100 Loss 0.9090 Accuracy 0.7769\n",
      "Epoch 6 Batch 150 Loss 0.9164 Accuracy 0.7747\n",
      "Epoch 6 Batch 200 Loss 0.9204 Accuracy 0.7744\n",
      "Epoch 6 Batch 250 Loss 0.9268 Accuracy 0.7732\n",
      "Epoch 6 Batch 300 Loss 0.9347 Accuracy 0.7719\n",
      "Epoch 6 Batch 350 Loss 0.9393 Accuracy 0.7709\n",
      "Epoch 6 Batch 400 Loss 0.9443 Accuracy 0.7698\n",
      "Epoch 6 Batch 450 Loss 0.9496 Accuracy 0.7687\n",
      "Epoch 6 Batch 500 Loss 0.9550 Accuracy 0.7675\n",
      "Epoch 6 Batch 550 Loss 0.9596 Accuracy 0.7666\n",
      "Epoch 6 Batch 600 Loss 0.9661 Accuracy 0.7654\n",
      "Epoch 6 Batch 650 Loss 0.9731 Accuracy 0.7642\n",
      "Epoch 6 Batch 700 Loss 0.9782 Accuracy 0.7632\n",
      "Epoch 6 Loss 0.9784 Accuracy 0.7631\n",
      "Time taken for 1 epoch: 301.060099363327 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.7551 Accuracy 0.8206\n",
      "Epoch 7 Batch 50 Loss 0.8488 Accuracy 0.7899\n",
      "Epoch 7 Batch 100 Loss 0.8693 Accuracy 0.7860\n",
      "Epoch 7 Batch 150 Loss 0.8856 Accuracy 0.7815\n",
      "Epoch 7 Batch 200 Loss 0.8932 Accuracy 0.7798\n",
      "Epoch 7 Batch 250 Loss 0.9013 Accuracy 0.7781\n",
      "Epoch 7 Batch 300 Loss 0.9087 Accuracy 0.7761\n",
      "Epoch 7 Batch 350 Loss 0.9144 Accuracy 0.7750\n",
      "Epoch 7 Batch 400 Loss 0.9183 Accuracy 0.7742\n",
      "Epoch 7 Batch 450 Loss 0.9233 Accuracy 0.7732\n",
      "Epoch 7 Batch 500 Loss 0.9298 Accuracy 0.7719\n",
      "Epoch 7 Batch 550 Loss 0.9371 Accuracy 0.7704\n",
      "Epoch 7 Batch 600 Loss 0.9424 Accuracy 0.7696\n",
      "Epoch 7 Batch 650 Loss 0.9485 Accuracy 0.7683\n",
      "Epoch 7 Batch 700 Loss 0.9540 Accuracy 0.7673\n",
      "Epoch 7 Loss 0.9541 Accuracy 0.7673\n",
      "Time taken for 1 epoch: 315.2778489589691 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.8361 Accuracy 0.7883\n",
      "Epoch 8 Batch 50 Loss 0.8400 Accuracy 0.7906\n",
      "Epoch 8 Batch 100 Loss 0.8602 Accuracy 0.7855\n",
      "Epoch 8 Batch 150 Loss 0.8703 Accuracy 0.7831\n",
      "Epoch 8 Batch 200 Loss 0.8749 Accuracy 0.7812\n",
      "Epoch 8 Batch 250 Loss 0.8833 Accuracy 0.7795\n",
      "Epoch 8 Batch 300 Loss 0.8891 Accuracy 0.7783\n",
      "Epoch 8 Batch 350 Loss 0.8937 Accuracy 0.7776\n",
      "Epoch 8 Batch 400 Loss 0.8963 Accuracy 0.7770\n",
      "Epoch 8 Batch 450 Loss 0.9010 Accuracy 0.7761\n",
      "Epoch 8 Batch 500 Loss 0.9068 Accuracy 0.7750\n",
      "Epoch 8 Batch 550 Loss 0.9125 Accuracy 0.7740\n",
      "Epoch 8 Batch 600 Loss 0.9199 Accuracy 0.7727\n",
      "Epoch 8 Batch 650 Loss 0.9265 Accuracy 0.7715\n",
      "Epoch 8 Batch 700 Loss 0.9305 Accuracy 0.7706\n",
      "Epoch 8 Loss 0.9305 Accuracy 0.7706\n",
      "Time taken for 1 epoch: 318.88809156417847 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8397 Accuracy 0.7807\n",
      "Epoch 9 Batch 50 Loss 0.8302 Accuracy 0.7926\n",
      "Epoch 9 Batch 100 Loss 0.8408 Accuracy 0.7896\n",
      "Epoch 9 Batch 150 Loss 0.8518 Accuracy 0.7873\n",
      "Epoch 9 Batch 200 Loss 0.8576 Accuracy 0.7856\n",
      "Epoch 9 Batch 250 Loss 0.8630 Accuracy 0.7843\n",
      "Epoch 9 Batch 300 Loss 0.8658 Accuracy 0.7837\n",
      "Epoch 9 Batch 350 Loss 0.8698 Accuracy 0.7829\n",
      "Epoch 9 Batch 400 Loss 0.8764 Accuracy 0.7816\n",
      "Epoch 9 Batch 450 Loss 0.8817 Accuracy 0.7805\n",
      "Epoch 9 Batch 500 Loss 0.8849 Accuracy 0.7798\n",
      "Epoch 9 Batch 550 Loss 0.8906 Accuracy 0.7788\n",
      "Epoch 9 Batch 600 Loss 0.8965 Accuracy 0.7778\n",
      "Epoch 9 Batch 650 Loss 0.9013 Accuracy 0.7767\n",
      "Epoch 9 Batch 700 Loss 0.9061 Accuracy 0.7758\n",
      "Epoch 9 Loss 0.9062 Accuracy 0.7758\n",
      "Time taken for 1 epoch: 183.79868841171265 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7906 Accuracy 0.8043\n",
      "Epoch 10 Batch 50 Loss 0.7916 Accuracy 0.7988\n",
      "Epoch 10 Batch 100 Loss 0.8096 Accuracy 0.7951\n",
      "Epoch 10 Batch 150 Loss 0.8216 Accuracy 0.7934\n",
      "Epoch 10 Batch 200 Loss 0.8264 Accuracy 0.7925\n",
      "Epoch 10 Batch 250 Loss 0.8351 Accuracy 0.7907\n",
      "Epoch 10 Batch 300 Loss 0.8432 Accuracy 0.7888\n",
      "Epoch 10 Batch 350 Loss 0.8482 Accuracy 0.7876\n",
      "Epoch 10 Batch 400 Loss 0.8517 Accuracy 0.7866\n",
      "Epoch 10 Batch 450 Loss 0.8572 Accuracy 0.7855\n",
      "Epoch 10 Batch 500 Loss 0.8629 Accuracy 0.7843\n",
      "Epoch 10 Batch 550 Loss 0.8681 Accuracy 0.7831\n",
      "Epoch 10 Batch 600 Loss 0.8734 Accuracy 0.7820\n",
      "Epoch 10 Batch 650 Loss 0.8802 Accuracy 0.7806\n",
      "Epoch 10 Batch 700 Loss 0.8852 Accuracy 0.7796\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-6\n",
      "Epoch 10 Loss 0.8858 Accuracy 0.7795\n",
      "Time taken for 1 epoch: 121.19188809394836 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6791 Accuracy 0.8076\n",
      "Epoch 11 Batch 50 Loss 0.7865 Accuracy 0.7992\n",
      "Epoch 11 Batch 100 Loss 0.7873 Accuracy 0.7984\n",
      "Epoch 11 Batch 150 Loss 0.8001 Accuracy 0.7963\n",
      "Epoch 11 Batch 200 Loss 0.8115 Accuracy 0.7941\n",
      "Epoch 11 Batch 250 Loss 0.8192 Accuracy 0.7928\n",
      "Epoch 11 Batch 300 Loss 0.8238 Accuracy 0.7919\n",
      "Epoch 11 Batch 350 Loss 0.8294 Accuracy 0.7907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 400 Loss 0.8345 Accuracy 0.7898\n",
      "Epoch 11 Batch 450 Loss 0.8384 Accuracy 0.7892\n",
      "Epoch 11 Batch 500 Loss 0.8439 Accuracy 0.7878\n",
      "Epoch 11 Batch 550 Loss 0.8501 Accuracy 0.7866\n",
      "Epoch 11 Batch 600 Loss 0.8564 Accuracy 0.7854\n",
      "Epoch 11 Batch 650 Loss 0.8621 Accuracy 0.7843\n",
      "Epoch 11 Batch 700 Loss 0.8657 Accuracy 0.7835\n",
      "Epoch 11 Loss 0.8658 Accuracy 0.7835\n",
      "Time taken for 1 epoch: 111.68400621414185 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.7410 Accuracy 0.7900\n",
      "Epoch 12 Batch 50 Loss 0.7775 Accuracy 0.7995\n",
      "Epoch 12 Batch 100 Loss 0.7825 Accuracy 0.7995\n",
      "Epoch 12 Batch 150 Loss 0.7911 Accuracy 0.7984\n",
      "Epoch 12 Batch 200 Loss 0.7954 Accuracy 0.7977\n",
      "Epoch 12 Batch 250 Loss 0.8016 Accuracy 0.7961\n",
      "Epoch 12 Batch 300 Loss 0.8043 Accuracy 0.7956\n",
      "Epoch 12 Batch 350 Loss 0.8101 Accuracy 0.7942\n",
      "Epoch 12 Batch 400 Loss 0.8158 Accuracy 0.7929\n",
      "Epoch 12 Batch 450 Loss 0.8217 Accuracy 0.7916\n",
      "Epoch 12 Batch 500 Loss 0.8271 Accuracy 0.7904\n",
      "Epoch 12 Batch 550 Loss 0.8316 Accuracy 0.7897\n",
      "Epoch 12 Batch 600 Loss 0.8362 Accuracy 0.7890\n",
      "Epoch 12 Batch 650 Loss 0.8406 Accuracy 0.7883\n",
      "Epoch 12 Batch 700 Loss 0.8456 Accuracy 0.7873\n",
      "Epoch 12 Loss 0.8458 Accuracy 0.7873\n",
      "Time taken for 1 epoch: 112.87268233299255 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.8392 Accuracy 0.7895\n",
      "Epoch 13 Batch 50 Loss 0.7493 Accuracy 0.8075\n",
      "Epoch 13 Batch 100 Loss 0.7598 Accuracy 0.8045\n",
      "Epoch 13 Batch 150 Loss 0.7627 Accuracy 0.8049\n",
      "Epoch 13 Batch 200 Loss 0.7737 Accuracy 0.8022\n",
      "Epoch 13 Batch 250 Loss 0.7814 Accuracy 0.8006\n",
      "Epoch 13 Batch 300 Loss 0.7846 Accuracy 0.7998\n",
      "Epoch 13 Batch 350 Loss 0.7918 Accuracy 0.7982\n",
      "Epoch 13 Batch 400 Loss 0.7979 Accuracy 0.7966\n",
      "Epoch 13 Batch 450 Loss 0.8025 Accuracy 0.7957\n",
      "Epoch 13 Batch 500 Loss 0.8082 Accuracy 0.7946\n",
      "Epoch 13 Batch 550 Loss 0.8129 Accuracy 0.7935\n",
      "Epoch 13 Batch 600 Loss 0.8175 Accuracy 0.7924\n",
      "Epoch 13 Batch 650 Loss 0.8223 Accuracy 0.7915\n",
      "Epoch 13 Batch 700 Loss 0.8272 Accuracy 0.7905\n",
      "Epoch 13 Loss 0.8275 Accuracy 0.7904\n",
      "Time taken for 1 epoch: 125.89482641220093 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.6697 Accuracy 0.8274\n",
      "Epoch 14 Batch 50 Loss 0.7217 Accuracy 0.8144\n",
      "Epoch 14 Batch 100 Loss 0.7330 Accuracy 0.8118\n",
      "Epoch 14 Batch 150 Loss 0.7437 Accuracy 0.8089\n",
      "Epoch 14 Batch 200 Loss 0.7536 Accuracy 0.8066\n",
      "Epoch 14 Batch 250 Loss 0.7596 Accuracy 0.8055\n",
      "Epoch 14 Batch 300 Loss 0.7662 Accuracy 0.8038\n",
      "Epoch 14 Batch 350 Loss 0.7727 Accuracy 0.8025\n",
      "Epoch 14 Batch 400 Loss 0.7785 Accuracy 0.8013\n",
      "Epoch 14 Batch 450 Loss 0.7820 Accuracy 0.8005\n",
      "Epoch 14 Batch 500 Loss 0.7879 Accuracy 0.7993\n",
      "Epoch 14 Batch 550 Loss 0.7957 Accuracy 0.7975\n",
      "Epoch 14 Batch 600 Loss 0.8009 Accuracy 0.7964\n",
      "Epoch 14 Batch 650 Loss 0.8057 Accuracy 0.7953\n",
      "Epoch 14 Batch 700 Loss 0.8100 Accuracy 0.7943\n",
      "Epoch 14 Loss 0.8101 Accuracy 0.7943\n",
      "Time taken for 1 epoch: 123.28925204277039 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.6984 Accuracy 0.8193\n",
      "Epoch 15 Batch 50 Loss 0.7254 Accuracy 0.8112\n",
      "Epoch 15 Batch 100 Loss 0.7308 Accuracy 0.8107\n",
      "Epoch 15 Batch 150 Loss 0.7367 Accuracy 0.8102\n",
      "Epoch 15 Batch 200 Loss 0.7443 Accuracy 0.8083\n",
      "Epoch 15 Batch 250 Loss 0.7493 Accuracy 0.8071\n",
      "Epoch 15 Batch 300 Loss 0.7556 Accuracy 0.8055\n",
      "Epoch 15 Batch 350 Loss 0.7613 Accuracy 0.8043\n",
      "Epoch 15 Batch 400 Loss 0.7651 Accuracy 0.8034\n",
      "Epoch 15 Batch 450 Loss 0.7700 Accuracy 0.8021\n",
      "Epoch 15 Batch 500 Loss 0.7745 Accuracy 0.8011\n",
      "Epoch 15 Batch 550 Loss 0.7795 Accuracy 0.8001\n",
      "Epoch 15 Batch 600 Loss 0.7841 Accuracy 0.7990\n",
      "Epoch 15 Batch 650 Loss 0.7887 Accuracy 0.7980\n",
      "Epoch 15 Batch 700 Loss 0.7933 Accuracy 0.7970\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-7\n",
      "Epoch 15 Loss 0.7933 Accuracy 0.7970\n",
      "Time taken for 1 epoch: 115.95500922203064 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.6879 Accuracy 0.8314\n",
      "Epoch 16 Batch 50 Loss 0.7175 Accuracy 0.8131\n",
      "Epoch 16 Batch 100 Loss 0.7213 Accuracy 0.8131\n",
      "Epoch 16 Batch 150 Loss 0.7253 Accuracy 0.8122\n",
      "Epoch 16 Batch 200 Loss 0.7307 Accuracy 0.8105\n",
      "Epoch 16 Batch 250 Loss 0.7377 Accuracy 0.8093\n",
      "Epoch 16 Batch 300 Loss 0.7440 Accuracy 0.8076\n",
      "Epoch 16 Batch 350 Loss 0.7462 Accuracy 0.8069\n",
      "Epoch 16 Batch 400 Loss 0.7498 Accuracy 0.8063\n",
      "Epoch 16 Batch 450 Loss 0.7533 Accuracy 0.8056\n",
      "Epoch 16 Batch 500 Loss 0.7589 Accuracy 0.8045\n",
      "Epoch 16 Batch 550 Loss 0.7648 Accuracy 0.8033\n",
      "Epoch 16 Batch 600 Loss 0.7697 Accuracy 0.8022\n",
      "Epoch 16 Batch 650 Loss 0.7753 Accuracy 0.8010\n",
      "Epoch 16 Batch 700 Loss 0.7804 Accuracy 0.7999\n",
      "Epoch 16 Loss 0.7807 Accuracy 0.7999\n",
      "Time taken for 1 epoch: 111.6572470664978 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.6257 Accuracy 0.8347\n",
      "Epoch 17 Batch 50 Loss 0.7016 Accuracy 0.8167\n",
      "Epoch 17 Batch 100 Loss 0.7071 Accuracy 0.8163\n",
      "Epoch 17 Batch 150 Loss 0.7146 Accuracy 0.8148\n",
      "Epoch 17 Batch 200 Loss 0.7200 Accuracy 0.8135\n",
      "Epoch 17 Batch 250 Loss 0.7243 Accuracy 0.8127\n",
      "Epoch 17 Batch 300 Loss 0.7280 Accuracy 0.8117\n",
      "Epoch 17 Batch 350 Loss 0.7327 Accuracy 0.8105\n",
      "Epoch 17 Batch 400 Loss 0.7361 Accuracy 0.8095\n",
      "Epoch 17 Batch 450 Loss 0.7409 Accuracy 0.8085\n",
      "Epoch 17 Batch 500 Loss 0.7470 Accuracy 0.8070\n",
      "Epoch 17 Batch 550 Loss 0.7513 Accuracy 0.8061\n",
      "Epoch 17 Batch 600 Loss 0.7558 Accuracy 0.8051\n",
      "Epoch 17 Batch 650 Loss 0.7607 Accuracy 0.8042\n",
      "Epoch 17 Batch 700 Loss 0.7664 Accuracy 0.8029\n",
      "Epoch 17 Loss 0.7667 Accuracy 0.8028\n",
      "Time taken for 1 epoch: 112.47545146942139 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.6869 Accuracy 0.8131\n",
      "Epoch 18 Batch 50 Loss 0.6842 Accuracy 0.8216\n",
      "Epoch 18 Batch 100 Loss 0.6906 Accuracy 0.8190\n",
      "Epoch 18 Batch 150 Loss 0.6949 Accuracy 0.8185\n",
      "Epoch 18 Batch 200 Loss 0.7032 Accuracy 0.8166\n",
      "Epoch 18 Batch 250 Loss 0.7094 Accuracy 0.8149\n",
      "Epoch 18 Batch 300 Loss 0.7117 Accuracy 0.8147\n",
      "Epoch 18 Batch 350 Loss 0.7171 Accuracy 0.8134\n",
      "Epoch 18 Batch 400 Loss 0.7205 Accuracy 0.8127\n",
      "Epoch 18 Batch 450 Loss 0.7243 Accuracy 0.8120\n",
      "Epoch 18 Batch 500 Loss 0.7303 Accuracy 0.8106\n",
      "Epoch 18 Batch 550 Loss 0.7339 Accuracy 0.8099\n",
      "Epoch 18 Batch 600 Loss 0.7401 Accuracy 0.8084\n",
      "Epoch 18 Batch 650 Loss 0.7451 Accuracy 0.8073\n",
      "Epoch 18 Batch 700 Loss 0.7500 Accuracy 0.8062\n",
      "Epoch 18 Loss 0.7501 Accuracy 0.8062\n",
      "Time taken for 1 epoch: 108.80322813987732 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.5646 Accuracy 0.8581\n",
      "Epoch 19 Batch 50 Loss 0.6679 Accuracy 0.8257\n",
      "Epoch 19 Batch 100 Loss 0.6733 Accuracy 0.8238\n",
      "Epoch 19 Batch 150 Loss 0.6860 Accuracy 0.8204\n",
      "Epoch 19 Batch 200 Loss 0.6907 Accuracy 0.8191\n",
      "Epoch 19 Batch 250 Loss 0.6953 Accuracy 0.8181\n",
      "Epoch 19 Batch 300 Loss 0.7025 Accuracy 0.8164\n",
      "Epoch 19 Batch 350 Loss 0.7042 Accuracy 0.8160\n",
      "Epoch 19 Batch 400 Loss 0.7114 Accuracy 0.8146\n",
      "Epoch 19 Batch 450 Loss 0.7157 Accuracy 0.8137\n",
      "Epoch 19 Batch 500 Loss 0.7213 Accuracy 0.8123\n",
      "Epoch 19 Batch 550 Loss 0.7257 Accuracy 0.8113\n",
      "Epoch 19 Batch 600 Loss 0.7299 Accuracy 0.8101\n",
      "Epoch 19 Batch 650 Loss 0.7341 Accuracy 0.8093\n",
      "Epoch 19 Batch 700 Loss 0.7389 Accuracy 0.8080\n",
      "Epoch 19 Loss 0.7391 Accuracy 0.8080\n",
      "Time taken for 1 epoch: 108.61773896217346 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.6096 Accuracy 0.8338\n",
      "Epoch 20 Batch 50 Loss 0.6559 Accuracy 0.8273\n",
      "Epoch 20 Batch 100 Loss 0.6652 Accuracy 0.8249\n",
      "Epoch 20 Batch 150 Loss 0.6711 Accuracy 0.8238\n",
      "Epoch 20 Batch 200 Loss 0.6772 Accuracy 0.8226\n",
      "Epoch 20 Batch 250 Loss 0.6815 Accuracy 0.8216\n",
      "Epoch 20 Batch 300 Loss 0.6868 Accuracy 0.8204\n",
      "Epoch 20 Batch 350 Loss 0.6903 Accuracy 0.8194\n",
      "Epoch 20 Batch 400 Loss 0.6950 Accuracy 0.8182\n",
      "Epoch 20 Batch 450 Loss 0.6990 Accuracy 0.8172\n",
      "Epoch 20 Batch 500 Loss 0.7044 Accuracy 0.8161\n",
      "Epoch 20 Batch 550 Loss 0.7098 Accuracy 0.8149\n",
      "Epoch 20 Batch 600 Loss 0.7141 Accuracy 0.8138\n",
      "Epoch 20 Batch 650 Loss 0.7191 Accuracy 0.8127\n",
      "Epoch 20 Batch 700 Loss 0.7235 Accuracy 0.8117\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-8\n",
      "Epoch 20 Loss 0.7239 Accuracy 0.8116\n",
      "Time taken for 1 epoch: 110.04910945892334 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "\n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "\n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "\n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "\n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "\n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "\n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "\n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "\n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to solve the problem of all the matter .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i 'm going to really quickly share with you a few of some magic things that happened.\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book i did for me that i did .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (14), usually from a call to set_ticks, does not match the number of ticklabels (13).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-c9ad4e8ca771>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"este é o primeiro livro que eu fiz.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'decoder_layer4_block2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Real translation: this is the first book i've ever done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-c65886c315f8>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(sentence, plot)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mplot_attention_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-77904dfe2add>\u001b[0m in \u001b[0;36mplot_attention_weights\u001b[1;34m(attention, sentence, result, layer)\u001b[0m\n\u001b[0;32m     23\u001b[0m         fontdict=fontdict, rotation=90)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n\u001b[0m\u001b[0;32m     26\u001b[0m                         if i < tokenizer_en.vocab_size], \n\u001b[0;32m     27\u001b[0m                        fontdict=fontdict)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tutorial\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tutorial\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tutorial\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1794\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1796\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_keyword_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"3.2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"minor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tutorial\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1715\u001b[0m             \u001b[1;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1717\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1718\u001b[0m                     \u001b[1;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m                     \u001b[1;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (14), usually from a call to set_ticks, does not match the number of ticklabels (13)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
